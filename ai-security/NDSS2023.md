# NDSS 2023

## Backdoor Attacks agiainse dataset distillation

+ 目标问题：数据蒸馏是为了将大规模数据中的知识蒸馏到较小规模的数据集中，使在较小数据集上训练的模型有跟在大规模数据上训练相近的效果。目前的方法主要关注资源利用率和模型可用性上的取舍，很少关注数据安全问题。
+ 解决方案：首次提出了图像领域在利用数据蒸馏模型得到的数据上进行训练的模型的后门攻击。提出了两种后门攻击方法NAIVEATTACK和DOORPING，NAIVEATTACK在数据蒸馏阶段向原始数据加入触发数据，DOORPING在整个蒸馏过程中迭代地更新触发数据。
+ 实验效果：NAIVEATTACK在某些实验数据上获得了很好的攻击成功率(ASR)结果，DROOPING在所有数据上都获得了更好的ASR分数。进行消融实验分析了可能影响攻击效果的因素，最后实验了若干防御策略，证明提出的攻击方法可以规避这些防御措施。

## REaaS: enabling adversarially robust downstream classifiers via robust encoder as a service

+ 目标问题：编码器即服务（服务提供商自行训练编码器并将其作为云服务API开放），下游分类器使用API得到输入数据，当输入数据具有扰动时下游分类器很容易受到对抗样本的攻击。研究服务商应当提供怎样的API，下游客户才能在最少的查询次数的前提下验证下游分类器的稳定性；以及运营商应当怎样预训练编码器，下游客户才能建造更加稳定的分类器。
+ 解决方案：设计了两种API让下游客户在最小化查询次数的前提下验证分类器的稳定性，并发现使用谱范数正则化项与训练模型可以让下游客户建造更加稳定的分类器。
+ 实验效果：

## Adversarial Robustness for tabular data through cost and utility awareness 

+ 目标问题：目前的对抗稳定性工作主要关注图像和文本领域的机器学习模型，没有考虑表格数据领域。这些模型无法捕捉到成本不明显的攻击，不同的攻击样本可以对实用性造成不同的影响。因此用于图像和文本领域的对抗稳定模型无法直接应用于表格数据领域
+ 解决方案：针对攻击能力和表格领域的攻击限制设计了新的成本和实用性敏感的威胁模型。提出了一种用于设计攻击和防御机制的框架，以保护模型对抗成本和实用性敏感的对抗样本。
+ 实验效果：在三个数据集上证明方法的有效性。

## Focusing on Pinocchio's Nose: a gradients scrutinizer to thwart split-learning hijacking attacks using intrinsic attributes

+ 目标问题：split-learning上的数据劫持攻击问题。攻击者可以劫持client发向server的结果（可以视作输入数据的隐层编码），训练一个自编码器来还原输入数据，从而完成劫持目标。SplitGuard是目前唯一抵御此类攻击的方法，但实验证明对SplitSpy自适应劫持攻击表现不佳。
+ 解决方案：提出了一种新的被动检测方法Gradients Scrutinizer，根据目标模型和可以模型之间的区别进行识别。目标模型中对于同一标签样本的梯度相似程度与不同标签样本的不同，而在可疑模型中两种相似程度类似。
+ 实验效果：实验结果证明提出的方法可以有效抵御split-learning劫持攻击和自适应对抗攻击。

## The "Beatrix" Resurrections: robust backdoor detection via gram matrices

+ 目标问题：已有的后门攻击抵御方案通常假设被污染的样本共享同样的触发器，但近期的后门攻击说明在动态后门攻击中触发器也在随着输入而变化。
+ 解决方案：提出了一种新的方法Beatrix，使用Gram matrix来捕捉表征的特征关联和高阶信息。通过学习普通数据中活跃模式的类别相关的统计信息，Beatrix可以通过捕捉活跃模式中的异常来识别污染数据。Beatrix进一步使用基于kernel的测试来在部队表征分布进行假设的情况下识别目标类别。
+ 实验效果：实验效果证明在识别动态后门上达到了91.1%的F1分数，而目前的最优方法只能达到36.9%。

## RoVISQ: reduction of video service quality via adversatial attacks on deep learning-based video compression

+ 目标问题：基于深度学习的视频压缩和下游分类系统的对抗攻击问题。
+ 解决方案：提出攻击框架RoVISQ，操作视频压缩模型的码率-失真关系来达到增加网络带宽和/或降低终端用户视频质量的目的。设计了对下游视频分类服务的针对性和无针对性攻击的目标。提出了一个输入无关的扰动，可以同时扰动视频压缩和分类系统。是第一个可以抗压缩的扰动方法。
+ 实验效果：在对抗训练，视频去噪和JPEG压缩等任务上进行测试，RoVISQ攻击会使峰值信噪比恶化高达5.6dB，使比特率增加～2.4倍，同时在下游分类器上实现超过90%的攻击成功率。

## Machine Unlearning of Features and Labels

+ 目标问题：从机器学习模型中移除信息的问题，目前的机器遗忘方法只能有效移除单个数据点，无法扩展到大量特征和标签需要移除的场景。
+ 解决方案：提出了第一个遗忘特征和标签的方法，方法建立在影响函数的概念基础上，并通过模型参数的封闭形式更新来实现遗忘。方法支持回溯调整训练数据的影响，从而改正数据泄露和隐私问题。
+ 实验效果：对于有强凸损失函数的学习模型，方法可以提供有理论保证的遗忘。对于非凸损失函数的学习模型，实操证明可以有效且比其他策略更高效地遗忘特征和标签。

## Fusion: efficient and secure inference resilient to malicious servers

+ 目标问题：安全机器学习推理问题，已有方法假设服务器是半诚实的，即遵守协议但尝试推理获得额外信息，但真实世界中服务器可能是有恶意的。已有关注服务器可能偏离协议的方法没有验证模型的准确性，同时将服务端模型和客户端输入的隐私一并保存。
+ 解决方案：提出Fusion，客户端将功用样本和自己的样本混合称为查询，作为多方计算的输入来共同进行安全推理。因为使用其质量模型或者偏离协议的服务端只能产生容易识别的结果，Fusion迫使服务端诚实运行。
+ 实验效果：实验证明Fusion比已有的恶意安全推理协议快48.06被并少用30.90倍的通信。在ResNet50模型上的ImageNet水平的推理比半诚实的协议快1.18倍，且少用2.64倍的通信量。

## Securing Federated sensitive Topic Classification against poisoning Attacks

+ 目标问题：针对敏感内容检测的污染攻击防御问题。污染攻击通过传播错误的模型更新来影响良性用户的识别准确性。
+ 解决方案：提出了一种基于联邦学习的分布式分类器来识别包含敏感内容的URL，解决以往离线/集中式分类器的局限性。为抵御污染攻击，根据主观逻辑和基于残差的攻击检测开发了一种稳健聚合方案。
+ 实验效果：理论分析，路径驱动模拟以及真实用户实验验证结果表明分类器可以高精度的检测敏感内容，快速学习新标签，并对污染攻击和输入不完美情况保持稳定。

## OBSan: an out-of-bound sanitizer to harden DNN executables

+ 目标问题：DL编译器生成的DNN可执行文件的安全问题。DL编译器将高阶DNN模型配置作为输入，为各种硬件架构生成DNN可执行文件，目前没有保护DNN可执行文件的方案。
+ 解决方案：提出OBSAN，用于检测DNN可执行文件越界行为的净化器。在前向和反向传播过程中的神经行为应当在有效范围内，超出有效范围的被定义为越界行为。OBSAN包含FOBSAN和BOBSAN，用于检测前向和反响传播中的越界行为。OBSAN被设计为DL编译器的额外通路，以与大模型集成。
+ 实验效果：对各种异常输入的评价表明OBSAN以低开销表现出良好的越界行为检测能力。

## BARS: local robustness certification for deep learning based traffic analysis systems

+ 目标问题：流量分析任务中的深度学习模型稳定性验证问题。
+ 解决方案：针对基于深度学习的流量分析系统的特征高多样性，模型设计多样性和对抗操作环境三个特点，设计BARS，一个基于边界自适应随机平滑的通用稳定性验证框架。BARS使用收敛于分类边界的优化的平滑噪声来获得更严格的稳健性保证。首先设计分布式transformer来生成最优平滑噪声，然后为噪声形状和噪声尺度设计了特殊的分布式函数和两个基于梯度的搜索方法来优化平滑噪声。
+ 实验效果：在三个基于DL的流量分析系统上进行测试，结果表明BARS可以得到更严格的稳定性保证。

## Anomaly Detection in the Open World: normality shift detection, explanation, and adaptation

+ 目标问题：概念漂移问题是在机器学习模型部署后，数据的分布和特性随着时间的推移而变化的问题。异常检测方法因为在零阳性（没有异常数据）情况下进行训练，所以对于异常行为的漂移具有免疫性，但正常行为发生漂移时则会有很严重的影响。当前方法主要集中在异常行为和监督学习的概念漂移上，对于零阳性异常检测的正常行为漂移则没有研究。
+ 解决方案：提出OWAD，一种在实践中检测、解释和适应正常性偏移的通用框架。OWAD通过无监督方式检测漂移，减少手动标记的开销，并通过分布级别的处理获得更好的适应表现。
+ 实验效果：实验证明OWAD可以通过更少的标记实现更好的适应表现。案例研究分析了正常性偏移，并为部署安全应用程序提供建议。

## BEAGLE: forensics of Deep Learning backdoor attack for better defence

+ 目标问题：针对基于DL的后门攻击的攻击检测问题。
+ 解决方案：提出一种新的模型后门检测技术，通过给定的各种包含后门触发词的输入，方法可以自动将其分解为干净输入和对应的触发词，然后将触发词根据其特性聚类以自动进行分类总结。后门扫描器随后进行自动扫描在其他模型中找到相同类型的后门实例。
+ 实验效果：在2532个预训练模型的10中流行攻击方式上与9个基准方法进行比较，结果证明方法得到贴近真实结果的触发词分解结果，扫描器可以发现其他基准无法发现的攻击。

## REDsec: running encrypted discretized neural networks in seconds

+ 目标问题：机器学习即服务（MLaaS）的敏感数据隐私保护问题，一种方法是使用完全同态加密进行机器学习计算。
+ 解决方案：提出REDsec框架，通过使用三元神经网络来优化基于完全同态加密的私人机器学习推理。REDsec提出一个新的数据复用方式来首次实现完全同态加密重的整数和位域的桥接，从而实现整数和位域的高效加法和激活等运算。提出的方法在一个新的GPU加速库(REDcuFHE)中包含。
+ 实验效果：在MNIST，CIFAR-10和ImageNet数据集上进行了推理实现，相较相关工作有表现提升。

## DOITRUST: dissecting on-chain compromised internet domains via Graph Learning

+ 目标问题：网站访问黑白名单的不完全和欠反应问题。
+ 解决方案：首先引入一种扩展图，通过爬取超链接，依据信任的传递性来创造有机增长的互联网域名允许列表，然后使用拓展图来凸显检测节点的缺失，恶意节点隐藏在沿被污染网站的路径上，称为“链上妥协”。为解决链上妥协问题，设计了两步的整体方案DoITrust，利用个体节点特征和拓扑结构分析。设计了一种半监督的嫌疑预测方案，来预测一个节点与妥协目标（被拒绝的节点）相关的概率。方案包括一个新的节点排名方法来使用拓扑信息，以及一种图学习方案来分离全剧全薄荷局部预测模型的训练。DoITrust还基于嫌疑预测结果提出有效的修剪策略来从抓取的途中删除高度可疑的节点并分析潜在的妥协指标。
+ 实验效果：使用少于1%的标记节点进行嫌疑预测时准确率达到了90%，超过了现有的基于节点和结构的方法。还证明DoITrust时可移植的，手动检查已发现的被污染节点表明至少有94.55%具有可疑内容。
