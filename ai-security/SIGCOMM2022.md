# SIGCOMM 2022

## GENET: automatic curriculum generation for learning adaptation in networking

+ 目标问题：强化学习的环境范围调整问题，在可选的决策范围较广时可能学习到次优的结果，在决策范围较窄时则可能削弱泛化能力。
+ 解决方案：提出了一种基于课程学习的新强化学习训练框架。宏观来说是逐渐将更加困难的环境加入训练过程而不是统一进行随机选择。为衡量环境困难程度使用了传统的基于规则的基准，如果当前模型效果远差于基准的规则模型则没有必要继续训练。GENET自动搜索满足要求的环境并将其加入训练。
+ 实验效果：在三个实例（自适应视频流，冲突控制和负载平衡）上的分析结果表明GENET可以得到比常规训练的RL策略和规则模型更好的RL策略。

> RL使用的场景是网络和系统自适应的问题，包括冲突控制，自适应字节流，负载均衡，无线资源调度和云调度。RL训练的环境是与网络相关的环境，比如与特定带宽模式的网络链接，延迟，队列长度等。

## LiteFLow: towards high-performance adaptive neural networks for kernel datapath

> 操作系统层面也有冲突控制，流调度和负载均衡？感觉得再看看

+ 目标问题：如何高效部署自适应神经网络来优化OS核数据通路函数的问题。部署在用户态则会面临高额的跨态沟通成本和反应迟钝问题，部署在内核态则会面临模型调整算法的复杂计算逻辑导致的性能衰减。
+ 解决方案：提出了一种用于为核数据通路高效部署神经网络的混合方案LiteFlow，将自适应神经网络解耦为部署在内核态的用于进行模型推理的高速通路和部署在用户态的用于模型调整的低速通路。
+ 实验效果：在三个数据通路功能（冲突控制，流调度和负载均衡）上进行测试，相较之前方法在三个功能上分别提升44.4%，33.7%和56.7%。

## Multi-resource interleaving for deep learning training

+ 目标问题：针对目前的DL调度程序只关注GPU资源分配，忽视在多类资源间分配任务的问题。
+ 解决方案：提出一种多源聚类调度程序，在多种资源上分配DL训练任务以提升资源利用率并缩短任务完成时间。基于DL任务分阶段迭代的特点，在同一资源的时间维度完成任务调度。使用带花树算法（blossom algorithm）找到使用两种类型资源的单GPU任务的最佳聚集方案，然后将方法推广到使用多种资源的多GPU任务上。
+ 实验效果：在64个GPU的集群上的测试表明Muri可以提升完成速度达3.6x，改进完成跨度达1.6x。

## DeepQueueNet: towards scalable and generalized network performance estimation with packet-level visibility

+ 目标问题：传统的网络模拟器基于离散的事件模拟，无法匹配网络规模的扩大，基于深度学习的方法的模拟结果的可视性不足，无法泛化到不同的场景。
+ 解决方案：结合可扩展泛化的连续模拟技术和离散的事件模拟以达到高延展性和包级别的可视性。对现代网络进行队列理论建模，识别出难以数学描述的和计算昂贵的部分，并用深度网络代替。提出的方法DeepQueueNet结合了网络的先验知识，并且支持任意结构和设备流量管理机制。
+ 实验效果：DeepQueueNet拥有与GPU数量近线性相关的速度提升，并且模拟精确度和第99百分位的往返时间都优于目前基于端到端DNN的模拟器。

## Practical GAN-based synthetic IP header trace generation using NetShare

> 啥啥啥，这说的都是啥

+ 目标问题：建立模型为网络任务（遥测，异常检测，provisioning）生成虚假的包和字节流的头痕迹
+ 解决方案：分析已有方法，总结存在的精确性，延展性和隐私问题，并提出端到端框架NetShare进行解决。
+ 实验效果：在6个包头部追踪任务上进行测试，发现精确度有46%的提升，满足下游对于精确度测量和候选方法级别排序的要求。
