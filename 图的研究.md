# 图的研究

> 要从什么角度来说呢，类别上有图的生成和挖掘，类型上有复杂网络，属性网络，异构网络，动态网络，还有处理单个网络和一系列网络的
> 还是要以问题为导向，看文章主要解决的是什么问题，每一类里面再按照图的类型进行划分，再下面再细分具体的问题，研究方法之类

## 生成图的研究

### 单个网络

#### 复杂网络

#### 属性网络

#### 异构网络

#### 动态网络

### 多个网络

#### 复杂网络

#### 属性网络

##### 图卷积变分自编码器-图变分对抗网络

Conditional Structure Generation through Graph Variational Generative Adversarial Network: 提出了条件结构生成问题，并使用图卷积神经网络构建了图变分生成对抗网络，用来生成具有灵活的属性-结构条件和排列不变性的属性网络

#### 异构网络

#### 动态网络

## 挖掘图的研究

### 单个网络

#### 复杂网络

##### 最小生成树发现

+ [ ] A fast minimum spanning tree algorithm based on K-means: 最小生成树发现，先用kmeans将网络分成若干个小网络，然后在小网络上发现最小生成树，最后把这些最小生成树连在一起

##### 社团发现

+ [ ] The Local Closure Coefficient_ A New Perspective On Network Clustering：定义了一个新的聚类紧凑程度指标，将二阶路径的头节点从中间节点换成两边节点
> 或许要看一下换过来的作用是什么，感觉还没看到指标的价值，或许可以和那个利用图神经网络进行神经网络结构探索的工作关联一下，因为那个用的是原来的clustering coefficient来描述搜索空间的
+ [ ] Community Detection using Diffusion Information：没太看懂，感觉看着挺像标签传播的，每个时间点只能观测到部分节点，节点的社团归属条件概率由相邻节点的归属来决定，预先指定了若干个cascade，然后观测节点在每个时间点是狗出现在这个cascade，按照出现的向量表示来计算两个节点之间边的权重，最后用这个权重来决定节点社团归属
> 看了个大概，不知道这数据都是怎么获得的
+ [ ]Detecting Community Structures in Networks by Label Propagation with Prediction of Percolation Transition：将percolation translation和标签传播结合，延迟出现巨型社团的时刻
> 不懂percolation transition，感觉价值有限
+ [ ] Local spectral Clustering for overlapping community detection：通过对已知社团的节点进行随机游走对网络进行采样，得到一个子图，然后首先假设所有节点均匀属于每一社团，通过在子图的拉普拉斯矩阵上计算1到$l$跳邻居的数目来更新节点属于每个社团的概率，对概率向量进行拼接后求正交基，并通过与拉氏矩阵相乘的方式循环更新正交基直至收敛，得到最后重叠社团的划分结果。
> 一搞正交基我就懵了，感觉有点图嵌入那味了
##### 图信号处理

1. 综述
    + Graph signal process part I:

##### 网络表示学习

1. 图对抗网络
   + [ ] GraphGAN: graph representation learning with generative adversarial nets: 利用对抗生成网络结合图表示学习中的生成式模型和辨别式模型。GraphGAN假设所有节点的连接遵循一个先验分布，边是这个分布的已观测样本。方法包含两个模型，生成器用于拟合真实的链接分布概率，判别器用于区分well-connected和ill-connected的节点对，计算节点之间存在边的可能性。方法利用嵌入好的向量，并使用sigmoid函数利用嵌入向量计算节点之间的连通可能性。
   > 需要看代码是如何实现的
   + [ ] Learning deep network representations with adversarially regularized autoencoders: 大部分网络嵌入模型根据采样得到的节点序列学习嵌入向量，以使低维向量保留局部特征或者全局重构能力。但是因为采样序列的稀疏性，学习到的表示向量很难用于模型泛化。使用对抗正则自编码器同时考虑局部特征和全局重构约束。联合对立封装在对抗训练过程中，以规避显示先验分布的要求，从而获得更好的泛化性能。首先使用随机游走对节点进行采样，然后利用LSTM作为自编码器的编码器和解码器。利用自编码器学到的向量为正样本，从先验分布中利用生成器采样得到负样本，最后输入判别器进行分辨，以两个分布的EMD距离的双重性是作为距离度量。

2. 图自编码器
   + 

#### 属性网络

##### 网络表示学习

1. 图卷积对抗网络

    + [ ] Deep graph infomax: 利用对抗神经网络解决以采样为基础的网络表示学习方法对于随机游走目标的依赖，并可用于迁移式和归纳式学习。利用图卷积自编码器为每个节点学习一个patch表征。同时以最大化局部互信息为自编码器学习目的，利用一个readout function将patch表征聚合为图级别的表征。同时通过负采样从图中获取负样本，然后在鉴别网络部分分别衡量正负样本的patch表征属于图级别表征对的概率，最后以最小化这个概率为目标进行训练。

    > 其实不太明白，卷积网络部分应该跟随机游走没什么关系，意思是重建邻接矩阵的学习方法对于结点的距离信息过于看重了吗？

    + [ ] Adversarial network embedding: 利用对抗生成网络解决图表示学习中对噪声数据敏感的问题。首先对数据进行预处理，产生更加稠密的输入特征矩阵，避免过拟合问题。结构保留模型利用已有的图表示学习方法学习节点表示向量，本文使用了DeepWalk的生成式变体，为每个节点随机采样多条同等长度的序列，游走概率由邻接矩阵中的权重决定，然后为每个节点训练一个目标表示和内容表示。对抗学习模型包含一个生成器和一个鉴别器，生成器将输入的高维特征映射为低维向量，使嵌入向量贴近先验分布，鉴别器将正例从嵌入向量中分辨出来。文章引入一个预设的先验分布，并假设所有节点向量都由这个分布产生。

    > 第一是这个随机游走是怎么处理节点特征的，第二是为所有节点特征预设同一个先验分布是不是合适，因为不同社团中的节点特征可能由不同的分布产生

    + GANE: A Generative Adversarial Network Embedding:
    + [ ] Adversarially regularized graph autoencoder for graph embedding: 大部分图嵌入方法着重于保留拓扑结构或者最小化重建误差，但忽略了隐层向量的数据分布，导致较差的嵌入结果。提出了一个新的嵌入框架，将网络的拓扑结构和文本信息编码为紧凑表示，解码器用于重建网络结构。隐层表示通过对抗训练策略约束为遵循先验分布。对抗训练策略用于分辨隐层向量是来自于真实分布还是图编码器。通过两层的图卷积自编码器将网络邻接矩阵和特征矩阵嵌入到隐层空间中，然后利用解码器重构邻接矩阵。使用多层感知器作为判别器，通过最小化二值判别器的交叉熵损失，嵌入向量可以在训练过程中被正则化。

2. 图自编码器
    + [ ] Variation autoencoder based network representation learning for classification: 原有工作只考虑网络表示学习的部分方面，比如边结构，节点信息或者部分整合(?)，这篇工作将网络结构和节点文本特征结合起来。使用Content2vec模型为节点文本生成属性特征，然后和网络的邻接矩阵拼接在一起作为变分自编码器的输入统一训练。模型中利用全连接层做降维映射，最终得到四段嵌入向量，分别作为文本信息和结构信息分布的均值和方差。然后从先验分布（高斯分布）中采样两个值作为扰动，通过线性函数结合均值和方差得到文本和结构的嵌入向量，再将两者拼接得到编码层最终习得的向量。最终通过解码层对输入进行还原，最小化输入输出向量之间的交叉熵和文本结构向量的KL散度。
    > 不太明白KL散度里面的$q(z_{ik}|x_i)$和$p(z_{ik})$是什么
    + [ ] Accelerated Attributed Network Embedding：用节点属性计算节点间的相似度，然后要求嵌入向量同时满足结构相似度和属性相似度，最终利用数学方式将学习方式进行分解，用分布式方式进行加速
    > 特点是用嵌入向量的欧几里得距离而不是余弦距离来衡量结构相似程度
    + [ ] Co-embedding Attributed Networks: 同时对结构和特征矩阵进行嵌入，利用全连接网络嵌入特征矩阵，利用图卷积网络嵌入邻接矩阵，双方均加入扰动项，然后分别重构特征矩阵和邻接矩阵
    >有个不太明白的地方，学两个表征干什么呢，这俩嵌入分别是干什么的，主要这个属性嵌入能干什么

3. 网络嵌入
    + [ ] context-aware network embedding for relation modeling：分别学习节点的结构嵌入和属性嵌入，在属性嵌入部分有注意力网络的雏形，针对不同的节点对学习不同的嵌入向量，最后将结构嵌入和属性嵌入做拼接作为最终的嵌入，在损失函数部分同时考虑结构间，属性间和结构-属性的相似程度

##### 节点分类

1. 对抗学习
   + [ ] Adversarial attacks on neural networks for graph data: 关注在二值属性网络上的节点分类问题，设计一个对抗模型，希望找到一个改变幅度低于一定的阈值的混淆网络，通过更改有限节点的特征和结构，使卷积网络对目标节点的分类结果与在原网络中的结果“距离”尽可能远。利用混淆网络和原网络的节点度数的概率分布，使用统计双样本测试来衡量混淆网络和原网络是否来自同一分布，对原网络的更改是否过于明显。在特征网络上利用随机游走，以从源特征节点到目标特征节点的随机游走概率来衡量两个特征共同出现是否是过于明显。在原图上计算出替代模型，然后在改变过于明显之前，依次从可攻击节点中选择进行结构和属性的混淆，并分别计算混淆和学习之后对目标结点的分类结果的“距离”，然后选择对距离改变最明显的混淆方式生成新图，最后返回改变最有效的混淆图。
   > （感觉已经有人做过了）这个可以当作是对抗学习网络的generator部分？不断生成图结构上几乎不可观测但是会改变学习结果的新图，然后通过判别器进行辨别？
##### 社团发现
   + [ ] Discovering Communities and Anomalies in Attributed Graphs_Interactive Visual Exploration and Summarization: visual exploration and summarization部分没有看，前面community discovering部分通过定义了一个新的标准normality来衡量社团结构和属性的一致性，通过节点属性的元素积来判断节点属性的相似度，并用一个权重向量来关注更主要的属性，最后提出了一个算法来发现normality最大的社团划分
   + [ ] Semantic Community Identification in Large Attribute Networks：比较明显的通过网络嵌入来做社团分类，为每个社团也初始化了一个属性向量，要求节点属性和所属的社团属性要尽可能相似，同时节点的社团归属矩阵可以重构出网络邻接矩阵。
   > 有点像我gci的矩阵版本

#### 异构网络

###### 网络表示学习

1. 图卷积对抗网络
   + Heterogeneous deep graph infomax: 


#### 动态网络

##### collaboration network

1. 网络嵌入
网络拓扑结构随时间变化

   + 特征值分解

    Attributed network embedding for learning in a dynamic environment: 
    High-order proximity preserved embedding for dynamic networks
    Error-bounded SVD restart on dynamic networks

   + skip-gram

    Dynamic network embedding: an extended approach for skip-gram based network embedding
    Continuous-time dynamic network embeddings

   + 自编码器

    Deep embedding method for dynamic graphs
    dyngraph2vec: capturing network dynamics using dynamic graph representation learning

   + 图卷积

    Representation learning over dynamic graphs

   + 其他方法

    Dynamic network embedding by modeling tradic closure process
    Streaming graph neural networks
    Dyn2vec: exploiting dynamic behavior using difference networks-based node mebeddings for classification

##### telephonecall network

网络上节点之间直接相互影响

1. 网络嵌入

Embedding Temporal Network via Neighborhood Formation:

#### 时空网络

##### 网络表示学习

1. 图卷积对抗网络
    + Spatio-temporal deep graph infomax: 

### 多个网络

#### 复杂网络

#### 属性网络

##### 图相似度计算

+ [ ] SimGNN_A Neural Network Approach to Fast Graph Similarity Computation：在利用GCN得到图的节点表示之后分别对两个图上节点间的和整个图的嵌入向量进行比较，最终将两个相似度向量拼接后经过全连接网络得到两个图的相似程度。
> 这个会不会改成无监督的，比如改成对抗学习或者那种优化互信息的方式
> 怎么得到整个图的嵌入的还没看，两个图的嵌入的相似程度计算方法像是用了个bilinear矩阵，然后结合了拼接的全连接层
#### 异构网络

#### 动态网络
