1. [ProtGNN: Towards Self-Explaining Graph Neural Networks](https://www.aminer.cn/pub/61a98af75244ab9dcb9532f9/protgnn-towards-self-explaining-graph-neural-networks?conf=AAAI%202022):
   
   * 图神经网络 可解释性
   
   * 解决已有的用简单模型解释无法真的找到推理过程的问题，提出引入原型学习使用基于case的推理过程进行解释，并应用于分类过程中。将输入与隐空间中的若干已学好的原型进行比较

2. [LUNAR: Unifying Local Outlier Detection Methods via Graph Neural Networks](https://www.aminer.cn/pub/61b6b9a05244ab9dcbf118d4/lunar-unifying-local-outlier-detection-methods-via-graph-neural-networks?conf=AAAI%202022):
   
   * 图神经网络 异常检测
   
   * 解决局部异常检测方法因为没有可训练参数无法应用于特定的数据集的问题，证明局部异常检测方法是图神经网络的特殊情况，然后提出了基于GNN的异常检测方法lunar

3. [Sparse Structure Learning via Graph Neural Networks for Inductive Document Classification](https://www.aminer.cn/pub/61b80b6e5244ab9dcbf49078/sparse-structure-learning-via-graph-neural-networks-for-inductive-document-classification?conf=AAAI%202022):
   
   * 图神经网络（应用） 文本分类
   
   * 解决原来GNN应用于文本分类时往往使用词共现网络建图导致的歧义，同义和动态语义依赖问题。提出了基于GNN的稀疏结构学习模型

4. [Orthogonal Graph Neural Networks](https://www.aminer.cn/pub/61a839655244ab9dcbb14d13/orthogonal-graph-neural-networks?conf=AAAI%202022):
   
   * 图神经网络 过平滑问题
   
   * 认为过平滑的原因是特征转换的设计不好导致的不稳定的前向归一化和返向梯度。因此提出了一种正交的特征转化方式，从三个方向维持特征转换的正交性

5. [Algorithmic Concept-based Explainable Reasoning](https://www.aminer.cn/pub/619e18966750f86487ee6329/algorithmic-concept-based-explainable-reasoning?conf=AAAI%202022):
   
   * 图神经网络 可解释性
   
   * 使用基于语义的解释性方法解决图神经网络的解释性问题，对readout机制做了修改。

6. [Qubit Routing using Graph Neural Network aided Monte Carlo Tree Search](https://www.aminer.cn/pub/606c65c091e0114248cd03ec/qubit-routing-using-graph-neural-network-aided-monte-carlo-tree-search?conf=AAAI%202022):
   
   * 量子计算机 蒙特卡洛树搜索 图神经网络
   
   * 谁他娘的没事干看这个

7. [AutoGCL: Automated Graph Contrastive Learning via Learnable View Generators](https://www.aminer.cn/pub/614a9ecb5244ab9dcbc38cf9/autogcl-automated-graph-contrastive-learning-via-learnable-view-generators?conf=AAAI%202022):
   
   * 图神经网络 自动机器学习 对比学习
   
   * 解决原油对比学习方法中视图生成过程方式单一无法自动适应输入数据或者保存语义结构的问题。利用自动机器学习生成用于对比学习的视图

8. [Graph-wise Common Latent Factor Extraction for Unsupervised Graph Representation Learning](https://www.aminer.cn/pub/61bc001b5244ab9dcba3faaa/graph-wise-common-latent-factor-extraction-for-unsupervised-graph-representation-learning?conf=AAAI%202022):
   
   * 图神经网络 无监督学习
   
   * 解决已有基于infomax的无监督学习方法对负样本质量依赖的问题，根据图一般根据同一个因素构建，提出模型学习图级别的通用隐因素，并用通用隐变量提升无监督学习效果

9. [Graph Transplant: Node Saliency-Guided Graph Mixup with Local Structure Preservation](https://www.aminer.cn/pub/618c89ec5244ab9dcb27cddd/graph-transplant-node-saliency-guided-graph-mixup-with-local-structure-preservation?conf=AAAI%202022):
   
   * 图神经网络 数据增强（图池化）
   
   * 解决由于不规则的图规模和连接性导致的数据增强方式难以应用的问题，提出了图级别的mixup数据增强方式，使用节点重要性信息选择有意义的子图并确定对应标签。

10. [Fuzzy Logic based Logical Query Answering on Knowledge Graph](https://www.aminer.cn/pub/610caefb5244ab9dcb1c083b/fuzzy-logic-based-logical-query-answering-on-knowledge-graph?conf=AAAI%202022):
    
    * 知识图谱 问答系统
    
    * 解决大部分逻辑操作不满足经典的逻辑系统的问题（没太懂），以及需要大量训练数据的问题，提出了一个查询嵌入框架，遵循模糊逻辑确定逻辑操作

11. [TempoQR: Temporal Question Reasoning over Knowledge Graphs](https://www.aminer.cn/pub/61b80b6b5244ab9dcbf48b78/tempoqr-temporal-question-reasoning-over-knowledge-graphs?conf=AAAI%202022):
    
    * 动态知识图谱（时间维度） 问答系统
    
    * 解决已有方法只能回答可以由单个动态知识图谱回答的问题的问题，提出了一个嵌入框架，可以回答时间跨度的复杂问题

12. [Enhanced Story Comprehension for Large Language Models through Dynamic Document-Based Knowledge Graphs](https://www.aminer.cn/pub/6215a4242c356815940386ad/enhanced-story-comprehension-for-large-language-models-through-dynamic-document-based-knowledge?conf=AAAI%202022):
    
    * 知识图谱 故事生成
    
    * 解决基于有限语义窗口的生成方法无法处理超长文本的问题，使用知识图谱创建富信息的prompts，更有利于创建完整故事。

13. 


