# 一些想法

### 不用乘法的网络表示学习方法

受到AdderNet启发，利用加减法代替以往图卷积网络中的乘法和卷积操作，看看是否可以提升效率。

图卷积网络主要执行两个任务，一个是聚合，一个是降维。这两步分别通过和相邻节点特征的加权以及和权重矩阵的相乘得到，~~所以主要任务是分辨哪一步是在做“卷积”的操作~~，与相邻节点特征的聚合可以通过GraphSAGE的拼接方式代替，所以主要是怎么处理权重矩阵。->目前想法是利用减法，但是拼接之后对权重矩阵也需要一个筛选，选择与节点对应的列来进行，达到滤波器的作用，这一步还没想好要怎么处理

### 利用标签传播的图表示学习

图表示学习主要完成对节点信号的滤波作用，方法是利用周围节点的信号的均值，聚合过程和标签传播方式很相似，可以利用标签传播的思想，将周围节点的信号进行聚合，然后逐个进行TF-IDF统计，利用出现次数最多的信号值作为新信号，并将出现信号值种类数过多的信号进行删除

这里主要问题是降维的效果并不可控，可能会出现只降一次的结果，因为第一次就已经把出现次数过多的筛掉了，后面就无法出现继续降维的效果。

### 利用NAS方法进行自动图表示学习

还没想好，目前的想法是学习一个不用很多层的自编码器，自动确定每层的类型和纬度，目的是摆脱训练和设计模型时的先验知识