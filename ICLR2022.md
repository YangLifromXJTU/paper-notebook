1. [Equivariant Subgraph Aggregation Networks](https://www.aminer.cn/pub/615e657b5244ab9dcbf22024/equivariant-subgraph-aggregation-networks?conf=ICLR%202022):
   
   * 图神经网络模型 表达能力提升 突破消息传递理论限制 子图采样方式
   
   * 将图表示为采样的子图的集合，使用等变结构处理

2. [Graph Neural Networks with Learnable Structural and Positional Representations](https://www.aminer.cn/pub/616ce5a15244ab9dcbacfc10/graph-neural-networks-with-learnable-structural-and-positional-representations?conf=ICLR%202022)：
   
   * 图神经网络模型 表达能力提升
   
   * 分离结构和位置表征学习，为节点学习位置嵌入

3. [Discovering Invariant Rationales for Graph Neural Networks](https://www.aminer.cn/pub/61f8a4c35aee126c0fee0426/discovering-invariant-rationales-for-graph-neural-networks?conf=ICLR%202022)：
   
   * 图神经网络  可解释性
   
   * 解决可解释性模型由于依赖数据偏差导致的在训练数据外表现差的现象。通过在训练分布上加入不同扰动生成扰动后分布，然后通过不同扰动分布找到其中不变的因果关系来解释GNN
   
   * （原来自己想过，但是觉得没有道理就没跟，不过跟了也跟不出什么来）

4. [Graph Condensation for Graph Neural Networks](https://www.aminer.cn/pub/6168f1a35244ab9dcbe2ffa3/graph-condensation-for-graph-neural-networks?conf=ICLR%202022)：
   
   * 图神经网络  大规模GNN训练  图简化
   
   * 把大网络简化成一个小网络，在小网络上训练的GNN可以应用于大网络

5. [Topological Graph Neural Networks](https://www.aminer.cn/pub/602cdfaf91e011c3e8f669fa/topological-graph-neural-networks?conf=ICLR%202022):
   
   * 图神经网络  表达能力提升
   
   * 解决GNN无法识别环等图内常见结构的问题，加了一个用于引入全局结构信息的网络层，提升WL测试能力

6. [Iterative Refinement Graph Neural Network for Antibody Sequence-Structure Co-design](https://www.aminer.cn/pub/6164fcc15244ab9dcb24d012/iterative-refinement-graph-neural-network-for-antibody-sequence-structure-co-design?conf=ICLR%202022):
   
   * 图生成 图神经网络
   
   * 将cdr序列和3d结构共同设计为图，在逐渐改进预测的全局结构的同时自回归的解开一个残基序列，预测的全局结构改进序列的选择

7. [Automated Self-Supervised Learning for Graphs](https://www.aminer.cn/pub/60c567e691e011368ce8c0f2/automated-self-supervised-learning-for-graphs?conf=ICLR%202022):
   
   * 图神经网络 自动机器学习 自监督学习
   
   * 解决自监督学习下游任务表现对上游任务选择敏感的问题，提出一个自动机器学习框架，自动选择上游任务的组合

8. [Node Feature Extraction by Self-Supervised Multi-scale Neighborhood Prediction](https://www.aminer.cn/pub/6180ac435244ab9dcb793a8f/node-feature-extraction-by-self-supervised-multi-scale-neighborhood-prediction?conf=ICLR%202022):
   
   * 图神经网络 数据预处理（节点特征提取）超多标签分类
   
   * 解决提取特征时没有考虑图结构的问题，提出一个自监督框架，将邻接矩阵作为标签输入，对bert进行微调

9. [Query Embedding on Hyper-relational Knowledge Graphs](https://www.aminer.cn/pub/60cd36a491e011329faa202e/query-embedding-on-hyper-relational-knowledge-graphs?conf=ICLR%202022):
   
   * 知识图谱 多跳逻辑推理 超关系
   
   * 超关系：知识图谱的边上有键值对提供额外信息
   
   * 解决超关系上的修饰信息没有充分利用的问题，利用GNN和查询嵌入，将超关系链接查询嵌入并搜索答案

10. [Chemical-Reaction-Aware Molecule Representation Learning](https://www.aminer.cn/pub/614a9eca5244ab9dcbc38b04/chemical-reaction-aware-molecule-representation-learning?conf=ICLR%202022):
    
    * 图神经网络 分子表示学习
    
    * 解决分子表示学习方法中要么不关注结构信息，要么过于强调结构而忽视泛化的问题。提出使用化学反应提升学习效果，使反应物的嵌入的和与生成物的嵌入的和相同。

11. [Graph-less Neural Networks: Teaching Old MLPs New Tricks via Distillation](https://www.aminer.cn/pub/616e37435244ab9dcbd1a8b1/graph-less-neural-networks-teaching-old-mlps-new-tricks-via-distillation?conf=ICLR%202022):
    
    * 图神经模型  可伸缩性  知识蒸馏
    
    * 解决大规模网络时邻域爆炸的问题，使用知识蒸馏结合GNN和MLP，解决图结构依赖问题

12. [Learn Locally, Correct Globally: A Distributed Algorithm for Training Graph Neural Networks](https://www.aminer.cn/pub/619472d35244ab9dcbd2dc0b/learn-locally-correct-globally-a-distributed-algorithm-for-training-graph-neural-networks?conf=ICLR%202022):
    
    * 图神经网络 训练方法 分布式（联邦？）学习
    
    * 解决图神经网络训练时依赖大量通信消耗和内存消耗问题，首先在本地训练一个GNN，然后将模型送到服务器上做周期平均。在服务器上做全局矫正对模型进行矫正

13. [Graph-Guided Network for Irregularly Sampled Multivariate Time Series](https://www.aminer.cn/pub/6164fcc75244ab9dcb24d947/graph-guided-network-for-irregularly-sampled-multivariate-time-series?conf=ICLR%202022):
    
    * 时间序列数据 数据矫正 时间序列分类
    
    * 解决时间序列数据由于传感器原因不连续和不规律等 噪声问题。使用基于消息传递机制和注意力机制的图方法对时间序列进行分类（识别提供序列的传感器间的关系），并找出误指定的序列

14. [Neural Link Prediction with Walk Pooling](https://www.aminer.cn/pub/6164fcc15244ab9dcb24ce9c/neural-link-prediction-with-walk-pooling?conf=ICLR%202022):
    
    * 图神经网络 链接预测
    
    * 解决链接预测模型使用图池化方式无法利用环和motif等结构信息的问题，提出了一种新的池化机制

15. [IGLU: Efficient GCN Training via Lazy Updates](https://www.aminer.cn/pub/61552aed5244ab9dcb23eaae/iglu-efficient-gcn-training-via-lazy-updates?conf=ICLR%202022):
    
    * 图神经网络 训练方法
    
    * 解决基于随机梯度下降的方法因为下降步骤要更新大部分节点导致的性能不佳，次级采样方法会导致偏差梯度的问题。方法捕捉前向传递的嵌入，并进行懒惰更新。

16. [Crystal Diffusion Variational Autoencoder for Periodic Material Generation](https://www.aminer.cn/pub/61664e625244ab9dcb455908/crystal-diffusion-variational-autoencoder-for-periodic-material-generation?conf=ICLR%202022):
    
    * 图生成 图神经网络 材料生成
    
    * 生成具有周期性结构的稳定材料

17. [From Stars to Subgraphs: Uplifting Any GNN with Local Structure Awareness](https://www.aminer.cn/pub/6163ab255244ab9dcbf95d72/from-stars-to-subgraphs-uplifting-any-gnn-with-local-structure-awareness?conf=ICLR%202022):
    
    * 图神经网络  表达能力
    
    * 新图神经网络模型，解决传统图神经网络模型表达能力不超过1-WL测试，超过的可伸缩性和泛化能力受限的问题。使用一个GNN以子图为单位学习节点的嵌入，远离类似将卷积核替换为GNN的CNN

18. [Cold Brew: Distilling Graph Node Representations with Incomplete or Missing Neighborhoods](https://www.aminer.cn/pub/618b38575244ab9dcb710ce2/cold-brew-distilling-graph-node-representations-with-incomplete-or-missing-neighborhoods?conf=ICLR%202022):
    
    * 图神经网络  严格冷启动场景
    
    * 解决孤立节点和结构强噪声节点的嵌入和分类问题。使用特征分布比例衡量GNN来解决严格冷启动问题的可能性，并选择最佳的模型

19. [Understanding over-squashing and bottlenecks on graphs via curvature](https://www.aminer.cn/pub/61a596635244ab9dcbdfe47f/understanding-over-squashing-and-bottlenecks-on-graphs-via-curvature?conf=ICLR%202022):
    
    * 图神经网络  过拥挤问题
    
    * 过拥挤：相邻节点的失真信息会导致依赖长距离交互的任务效果下降
    
    * 提出了基于边的组合弯曲方法，证明负向弯曲会造成过拥挤问题

20. [Predicting Physics in Mesh-reduced Space with Temporal Attention](https://www.aminer.cn/pub/61ef6ad35244ab9dcb67db22/predicting-physics-in-mesh-reduced-space-with-temporal-attention?conf=ICLR%202022):
    
    * 图神经网络 下一步预测 动态图？
    
    * 解决下一步预测模型短期时间注意力机制的限制导致的首误差累积和传播影响的问题。使用编码解码结构学习简单的相互协调的表示，用类transformer的注意力机制捕捉长时间依赖

21. 
